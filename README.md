# üö¢ Titanic - Machine Learning from Disaster (Kaggle)

Ce projet Kaggle consiste √† pr√©dire la survie des passagers du Titanic en utilisant des mod√®les de machine learning.  
Il s'agit d'un **classique projet de classification supervis√©e**, tr√®s utilis√© pour apprendre la Data Science.

---

##  Objectif

Utiliser les donn√©es disponibles (sexe, √¢ge, classe, famille, tarif, etc.) pour pr√©dire si un passager a surv√©cu ou non au naufrage du Titanic.

---

##  Score obtenu

**‚úÖ Score public Kaggle : `0.78468`**  
Ce score d√©passe la baseline (`gender_submission.csv` ‚âà 0.765).

---

##  Mod√®le utilis√©

- **Random Forest Classifier** (`sklearn`)
- Avec :
  - **n_estimators = 200**
  - **max_depth = 8**
- √âvalu√© en validation crois√©e (`train_test_split` 80/20)

---

## üîß Feature Engineering

Voici les principales features cr√©√©es pour am√©liorer le mod√®le :

| Feature        | Description                                          |
|----------------|------------------------------------------------------|
| `FamilySize`   | SibSp + Parch + 1                                    |
| `IsAlone`      | 1 si le passager est seul, sinon 0                   |
| `Title`        | Extraction du titre (`Mr`, `Mrs`, `Miss`, etc.)     |
| `Sex`          | Encod√© en binaire                                    |
| `Embarked`     | Encodage one-hot                                     |

---

##  Nettoyage & Pr√©paration

- Suppression des colonnes : `Cabin`, `Ticket`, `Name`
- Imputation des valeurs manquantes (`Age`, `Embarked`, `Fare`)
- Encodage des variables cat√©gorielles (`Sex`, `Embarked`, `Title`)

---

## üìÅ Contenu du d√©p√¥t

| Fichier                       | R√¥le                                    |
|------------------------------|-----------------------------------------|
| `titanic_notebook.ipynb`     | Notebook complet avec code + commentaires |
| `submission.csv`             | Pr√©dictions finales envoy√©es √† Kaggle    |
| `README.md`                  | Documentation du projet                  |

---

## Id√©es d'am√©lioration

- Utiliser **XGBoost** ou **LightGBM**
- Cr√©er des variables comme `Deck`, `FarePerPerson`, `AgeGroup`
- Tuning d'hyperparam√®tres avec `GridSearchCV`
- Validation crois√©e `StratifiedKFold` au lieu de simple split

---

##  A propos

Projet r√©alis√© dans le cadre de son apprentissage en Data Science.  

---

## üß† Comp√©tences mobilis√©es

- Pandas, Numpy, Matplotlib, Seaborn
- Feature engineering, nettoyage de donn√©es
- Mod√©lisation supervis√©e avec `sklearn`
- √âvaluation de mod√®les (accuracy, classification report)
